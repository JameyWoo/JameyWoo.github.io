<!DOCTYPE html>
<html lang="en-us">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='一. 什么是自编码器 自动编码器 autoencoder, 简单表现编码器为将一组数据进行压缩编码(降维), 解码器将这组数据恢复成高维的数据. 这种编码和解码的过程不是无损的, 因此最终的输出和输入是有一些差异的, 且非常依赖于训练的数据集.
如图所示  
如上面这张图所示, 对于一个简单的三层线性神经网络组成的自编码器, 我们在进行神经网络的搭建过程中, 将(input, hidden) 这个过程叫做编码器, 将(hidden, output) 这个过程叫做解码器. 对于mnist数据集而言, 它的维度变化是 784 -&amp;gt; x -&amp;gt; 784, 其中, x &amp;lt; 784, 是编码的维度.
 二. 有什么作用 1) 图像去噪 看上去很强啊  
2) 可视化降维  三. 如何实现 训练神经网络需要定义损失函数, 那么这个自编码器的损失衡量值是什么?
衡量损失的值是由网络的输出结果和输入决定的. 也就是说, 是由这两个784维数据的差别决定的.
1) 全连接层实现 首先定义一个神经网络
class Autoencoder(nn.Module): def __init__(self, encoding_dim): super(Autoencoder, self).__init__() ## encoder ## self.encoder = nn.Linear(784, encoding_dim) ## decoder ## self.'><title>自编码器AutoEncoder</title>

<link rel='canonical' href='https://example.com/p/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8autoencoder/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='自编码器AutoEncoder'>
<meta property='og:description' content='一. 什么是自编码器 自动编码器 autoencoder, 简单表现编码器为将一组数据进行压缩编码(降维), 解码器将这组数据恢复成高维的数据. 这种编码和解码的过程不是无损的, 因此最终的输出和输入是有一些差异的, 且非常依赖于训练的数据集.
如图所示  
如上面这张图所示, 对于一个简单的三层线性神经网络组成的自编码器, 我们在进行神经网络的搭建过程中, 将(input, hidden) 这个过程叫做编码器, 将(hidden, output) 这个过程叫做解码器. 对于mnist数据集而言, 它的维度变化是 784 -&amp;gt; x -&amp;gt; 784, 其中, x &amp;lt; 784, 是编码的维度.
 二. 有什么作用 1) 图像去噪 看上去很强啊  
2) 可视化降维  三. 如何实现 训练神经网络需要定义损失函数, 那么这个自编码器的损失衡量值是什么?
衡量损失的值是由网络的输出结果和输入决定的. 也就是说, 是由这两个784维数据的差别决定的.
1) 全连接层实现 首先定义一个神经网络
class Autoencoder(nn.Module): def __init__(self, encoding_dim): super(Autoencoder, self).__init__() ## encoder ## self.encoder = nn.Linear(784, encoding_dim) ## decoder ## self.'>
<meta property='og:url' content='https://example.com/p/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8autoencoder/'>
<meta property='og:site_name' content='Example Site'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2019-08-14T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2019-08-14T00:00:00&#43;00:00'/>
<meta name="twitter:title" content="自编码器AutoEncoder">
<meta name="twitter:description" content="一. 什么是自编码器 自动编码器 autoencoder, 简单表现编码器为将一组数据进行压缩编码(降维), 解码器将这组数据恢复成高维的数据. 这种编码和解码的过程不是无损的, 因此最终的输出和输入是有一些差异的, 且非常依赖于训练的数据集.
如图所示  
如上面这张图所示, 对于一个简单的三层线性神经网络组成的自编码器, 我们在进行神经网络的搭建过程中, 将(input, hidden) 这个过程叫做编码器, 将(hidden, output) 这个过程叫做解码器. 对于mnist数据集而言, 它的维度变化是 784 -&amp;gt; x -&amp;gt; 784, 其中, x &amp;lt; 784, 是编码的维度.
 二. 有什么作用 1) 图像去噪 看上去很强啊  
2) 可视化降维  三. 如何实现 训练神经网络需要定义损失函数, 那么这个自编码器的损失衡量值是什么?
衡量损失的值是由网络的输出结果和输入决定的. 也就是说, 是由这两个784维数据的差别决定的.
1) 全连接层实现 首先定义一个神经网络
class Autoencoder(nn.Module): def __init__(self, encoding_dim): super(Autoencoder, self).__init__() ## encoder ## self.encoder = nn.Linear(784, encoding_dim) ## decoder ## self.">
    </head>
    <body class="
    article-page has-toc
">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="https://example.com" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>Back</span>
            </a>
        </div>
    
<main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" >
                深度学习
            </a>
        
    </header>
    

    <h2 class="article-title">
        <a href="/p/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8autoencoder/">自编码器AutoEncoder</a>
    </h2>

    

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Aug 14, 2019</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    4 minute read
                </time>
            </div>
        
    </footer>
    
</div>
</header>

    <section class="article-content">
    <h2 id="一-什么是自编码器">一. 什么是自编码器</h2>
<p>自动编码器 autoencoder, 简单表现编码器为将一组数据进行压缩编码(降维), 解码器将这组数据恢复成高维的数据. 这种编码和解码的过程不是无损的, 因此最终的输出和输入是有一些差异的, 且非常依赖于训练的数据集.</p>
<p>如图所示
<figure 
	>
	<a href="/images/20190814_1.png" >
		<img src="/images/20190814_1.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<p>如上面这张图所示, 对于一个简单的三层线性神经网络组成的自编码器, 我们在进行神经网络的搭建过程中, 将(input, hidden) 这个过程叫做编码器, 将(hidden, output) 这个过程叫做解码器. 对于mnist数据集而言, 它的维度变化是 784 -&gt; x -&gt; 784, 其中, x &lt; 784, 是编码的维度.</p>
<hr>
<h2 id="二-有什么作用">二. 有什么作用</h2>
<h3 id="1-图像去噪">1) 图像去噪</h3>
<p>看上去很强啊
<figure 
	>
	<a href="/images/20190814_2.png" >
		<img src="/images/20190814_2.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<h3 id="2-可视化降维">2) 可视化降维</h3>
<hr>
<h2 id="三-如何实现">三. 如何实现</h2>
<p>训练神经网络需要定义损失函数, 那么这个自编码器的损失衡量值是什么?</p>
<p>衡量损失的值是由网络的输出结果和输入决定的. 也就是说, 是由这两个784维数据的差别决定的.</p>
<h3 id="1-全连接层实现">1) 全连接层实现</h3>
<p>首先定义一个神经网络</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Autoencoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoding_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Autoencoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1">## encoder ##</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="n">encoding_dim</span><span class="p">)</span>
        
        <span class="c1">## decoder ##</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_dim</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
        

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># define feedforward behavior </span>
        <span class="c1"># and scale the *output* layer with a sigmoid activation function</span>
<span class="c1">#         print(x.shape)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># initialize the NN</span>
<span class="n">encoding_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span><span class="n">encoding_dim</span><span class="p">)</span>
</code></pre></div><p>定义损失函数和优化器</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="cp"># specify loss function
</span><span class="cp"></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="cp"># specify loss function
</span><span class="cp"></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</code></pre></div><p>训练过程, 一共20个epochs, 话说pytorch还真慢, 这么简单的网络都要训练好一会</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="c1"># number of epochs to train the model</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">20</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># monitor training loss</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    
    <span class="c1">###################</span>
    <span class="c1"># train the model #</span>
    <span class="c1">###################</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1"># _ stands in for labels, here</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data</span>
        <span class="c1"># flatten images</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># clear the gradients of all optimized variables</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># forward pass: compute predicted outputs by passing inputs to the model</span>
<span class="c1">#         print(images.shape)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="c1"># calculate the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>
        <span class="c1"># backward pass: compute gradient of the loss with respect to model parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># perform a single optimization step (parameter update)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># update running training loss</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            
    <span class="c1"># print avg training statistics </span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Training Loss: </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">epoch</span><span class="p">,</span> 
        <span class="n">train_loss</span>
        <span class="p">))</span>
</code></pre></div><p>训练过程的损失变化</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="n">Epoch</span><span class="p">:</span> <span class="mi">1</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.342308</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">2</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.081272</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">3</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.058724</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">4</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.051274</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">5</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.047382</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">6</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.044760</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">7</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.043184</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">8</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.042066</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">9</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.041246</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">10</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.040589</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">11</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.040059</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">12</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.039646</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">13</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.039272</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">14</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.038980</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">15</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.038733</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">16</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.038524</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">17</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.038328</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">18</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.038162</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">19</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.038012</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">20</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.037874</span>
</code></pre></div><p>那么效果如何呢? 上面一排是输入图像, 下面一排是输出图像. 经过自编码器之后, 还原度还是很高的.</p>
<p><figure 
	>
	<a href="/images/20190814_3.png" >
		<img src="/images/20190814_3.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<h3 id="2-测试-对有噪声图像的自编码">2) 测试: 对有噪声图像的自编码</h3>
<p>首先查看一张图片</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="n">a_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a_img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a_img</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">a_img</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">a_img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</code></pre></div><p><figure 
	>
	<a href="/images/20190814_4.png" >
		<img src="/images/20190814_4.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure>
然后向其中加入噪声</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="n">a_img_x</span> <span class="o">=</span> <span class="n">a_img</span> <span class="o">+</span> <span class="mf">0.08</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">a_img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">a_img_x</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</code></pre></div><p>这是加入噪声之后的图片, 可以看出差别还是很大的. 那么我们的编码器能还原出如何的效果呢?
<figure 
	>
	<a href="/images/20190814_5.png" >
		<img src="/images/20190814_5.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="n">a_img_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">a_img_x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a_img_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">output_img</span> <span class="o">=</span> <span class="n">a_img_output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">output_img</span> <span class="o">=</span> <span class="n">output_img</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</code></pre></div><p>这是还原后的, 说实话看到这个图片我心里也是很惊讶的. 就在于加入那么多噪声之后, 居然还可以还原的如此清晰. 当然这是对于MNIST数据集而言, 这个数据集比较简单.
<figure 
	>
	<a href="/images/20190814_6.png" >
		<img src="/images/20190814_6.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<h3 id="3-卷积层实现">3) 卷积层实现</h3>
<p>不同之处在于定义自编码器的神经网络结构
如图所示
<figure 
	>
	<a href="/images/20190814_7.png" >
		<img src="/images/20190814_7.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure>
可以看到在decoder中经过了两个反卷积层, <!-- raw HTML omitted -->但是由于水平有限, 这个反卷积层看着好奇怪, 不知道是怎么反卷积的. <!-- raw HTML omitted --></p>
<p>pytorch实现</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="c1"># define the NN architecture</span>
<span class="k">class</span> <span class="nc">ConvAutoencoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvAutoencoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1">## encoder layers ##</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>        
        
        <span class="c1">## decoder layers ##</span>
        <span class="c1">## a kernel of 2 and a stride of 2 will increase the spatial dims by 2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t_conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t_conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1">## encode ##</span>
        
        <span class="c1">## decode ##</span>
        <span class="c1">## apply ReLu to all hidden layers *except for the output layer</span>
        <span class="c1">## apply a sigmoid to the output layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">t_conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">t_conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
                
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># initialize the NN</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ConvAutoencoder</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div><p>训练起来比全连接层的网络还要慢很多, 而损失值的降低也慢很多, 不像之前从epoch 1 到 epoch 2 直接就断崖式下跌了. 下面是损失值的变化过程, 只训练了 15个epoch. 从损失之上看这个效果好像差很多?</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="n">Epoch</span><span class="p">:</span> <span class="mi">1</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.448799</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">2</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.266815</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">3</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.251290</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">4</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.240823</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">5</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.231836</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">6</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.220550</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">7</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.210341</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">8</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.202768</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">9</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.197010</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">10</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.193259</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">11</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.190589</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">12</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.188406</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">13</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.186529</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">14</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.184983</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">15</span> 	<span class="n">Training</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.183579</span>
</code></pre></div><p>观察下图的数字9的话, 可以看到损失了不少.
<figure 
	>
	<a href="/images/20190814_8.png" >
		<img src="/images/20190814_8.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<p><strong>再看看噪声图片的处理能力如何</strong></p>
<p>原图:
<figure 
	>
	<a href="/images/20190814_9.png" >
		<img src="/images/20190814_9.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure>
加入噪声:
<figure 
	>
	<a href="/images/20190814_10.png" >
		<img src="/images/20190814_10.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure>
经过自编码器
<figure 
	>
	<a href="/images/20190814_11.png" >
		<img src="/images/20190814_11.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure>
呃, 效果似乎有点不是很对, 可能是训练的epoch太少了, 毕竟我们可以前面看到训练15个epoch的损失值还是达到了0.18, 而在全连接层的简单自编码器上第二个epoch的损失值就达到了0.08</p>
<hr>
<h2 id="四-一些小细节">四. 一些小细节</h2>
<ol>
<li>
<p>numpy 的 squeeze 函数
<a class="link" href="https://blog.csdn.net/zenghaitao0128/article/details/78512715"  target="_blank" rel="noopener"
    >参考博客</a>
作用：<strong>从数组的形状中删除单维度条目，即把shape中为1的维度去掉</strong></p>
</li>
<li>
<p>给MNIST图片加入噪声的方法</p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="n">test_img_x</span> <span class="o">=</span> <span class="n">test_img</span> <span class="o">+</span> <span class="mf">0.08</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">test_img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div><p>就是加入一些随机值, 在原图的基础上进行小幅度修改.</p>

</section>


    <footer class="article-footer">
    

    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
</article>

    <aside class="related-contents--wrapper">
    
    
        <h2 class="section-title">Related contents</h2>
        <div class="related-contents">
            <div class="flex article-list--tile">
                
                    
<article class="">
    <a href="/p/introduction-to-pytorch-%E7%AC%94%E8%AE%B0/">
        
        

        <div class="article-details">
            <h2 class="article-title">Introduction to PyTorch 笔记</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/%E5%88%A9%E7%94%A8%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%BF%9B%E8%A1%8C%E8%8A%B1%E7%9A%84%E5%88%86%E7%B1%BB/">
        
        

        <div class="article-details">
            <h2 class="article-title">利用迁移学习进行花的分类</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/darknet-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BC%80%E6%BA%90%E5%BA%93%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">
        
        

        <div class="article-details">
            <h2 class="article-title">Darknet  目标检测开源库学习记录</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/%E4%BD%BF%E7%94%A8face_recognition%E8%BF%9B%E8%A1%8C%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B/">
        
        

        <div class="article-details">
            <h2 class="article-title">使用face_recognition进行人脸特征检测</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/opencv-python-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E5%B0%9D%E8%AF%95knn%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
        
        

        <div class="article-details">
            <h2 class="article-title">Opencv Python 人脸识别尝试——knn与深度学习</h2>
        </div>
    </a>
</article>
                
            </div>
        </div>
    
</aside>

     
    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hugo-theme-stack" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (DISQUS) {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2021 Example Site
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.2.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">
            <section class="widget archives">
                <div class="widget-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



                </div>
                <h2 class="widget-title section-title">Table of contents</h2>
                
                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li><a href="#一-什么是自编码器">一. 什么是自编码器</a></li>
    <li><a href="#二-有什么作用">二. 有什么作用</a>
      <ol>
        <li><a href="#1-图像去噪">1) 图像去噪</a></li>
        <li><a href="#2-可视化降维">2) 可视化降维</a></li>
      </ol>
    </li>
    <li><a href="#三-如何实现">三. 如何实现</a>
      <ol>
        <li><a href="#1-全连接层实现">1) 全连接层实现</a></li>
        <li><a href="#2-测试-对有噪声图像的自编码">2) 测试: 对有噪声图像的自编码</a></li>
        <li><a href="#3-卷积层实现">3) 卷积层实现</a></li>
      </ol>
    </li>
    <li><a href="#四-一些小细节">四. 一些小细节</a></li>
  </ol>
</nav>
                </div>
            </section>
        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
